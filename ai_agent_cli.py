"""
AI Agent CLI - Ù…Ø¹ Ø¯Ø¹Ù… Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±
"""

import sys
import json
import os
import base64
from openai import OpenAI

client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

KNOWLEDGE_BASE = {
    "contact": {
        "keywords": ["Ø±Ù‚Ù…", "Ù‡Ø§ØªÙ", "ØªÙˆØ§ØµÙ„", "Ø§ØªØµØ§Ù„", "Ù…ÙˆØ¨Ø§ÙŠÙ„", "Ø¬ÙˆØ§Ù„", "Ø§ÙŠÙ…ÙŠÙ„", "Ø¨Ø±ÙŠØ¯", "email", "phone"],
        "info": """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø¬Ø§Ù…Ø¹Ø© Ø¹Ù…Ø§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
ðŸ“ž Ø§Ù„Ù‡Ø§ØªÙ: 0798877440
ðŸŒ Ø§Ù„Ù…ÙˆÙ‚Ø¹: https://www.aau.edu.jo/ar
ðŸ“ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†: Ø´Ø§Ø±Ø¹ Ø§Ù„Ø£Ø±Ø¯Ù†ØŒ Ù…Ø¨ÙŠØ³ - Ø¹Ù…Ø§Ù†ØŒ Ø§Ù„Ø£Ø±Ø¯Ù†
â° Ø£ÙˆÙ‚Ø§Øª Ø§Ù„Ø¹Ù…Ù„: Ù…Ù† Ø§Ù„Ø£Ø­Ø¯ Ø¥Ù„Ù‰ Ø§Ù„Ø®Ù…ÙŠØ³"""
    },
    "technest": {
        "keywords": ["ØªÙƒÙ†Ø³Øª", "ÙØ±ÙŠÙ‚", "team", "technest"],
        "info": """ÙØ±ÙŠÙ‚ TechNest - ÙØ±ÙŠÙ‚ Ø±Ø§Ø¦Ø¹ Ù…Ù† Ø¬Ø§Ù…Ø¹Ø© Ø¹Ù…Ø§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:
ðŸŽ® Ù…ØªØ®ØµØµÙˆÙ† ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ø£Ù„Ø¹Ø§Ø¨ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
ðŸ’¡ ÙØ±ÙŠÙ‚ Ù…Ø¨Ø¯Ø¹ ÙˆÙ…ÙˆÙ‡ÙˆØ¨ Ù…Ù† Ø·Ù„Ø§Ø¨ ÙˆØ®Ø±ÙŠØ¬ÙŠ Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©
ðŸ”— Ø§Ù„Ù…ÙˆÙ‚Ø¹: https://technestjo.dev
ðŸ“§ Ø§Ù„Ø§Ù†Ø¶Ù…Ø§Ù…: https://technestjo.dev/join-us"""
    }
}

tools = [
    {
        "type": "function",
        "function": {
            "name": "search_aau_knowledge",
            "description": "Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙØ© Ø¬Ø§Ù…Ø¹Ø© Ø¹Ù…Ø§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ù„Ø¨Ø­Ø« Ø¹Ù†Ù‡"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

def search_aau_knowledge(query):
    query_lower = query.lower()
    for category, data in KNOWLEDGE_BASE.items():
        keywords = data.get("keywords", [])
        if any(keyword in query_lower for keyword in keywords):
            return data.get("info", "Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")
    return f"Ù„Ù… Ø£Ø¬Ø¯ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† '{query}'. Ø§ØªØµÙ„ Ø¹Ù„Ù‰ 0798877440"

SYSTEM_MESSAGE = """Ø£Ù†Øª Tec ðŸ¤–ØŒ Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ ÙÙŠ Ø¬Ø§Ù…Ø¹Ø© Ø¹Ù…Ø§Ù† Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.
- Ø§Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
- Ø¥Ø°Ø§ ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØµÙˆØ±Ø©ØŒ Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙˆØ£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙˆØ±Ø©
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
- ÙƒÙ† ÙˆØ¯ÙŠØ§Ù‹ ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ§Ù‹
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥ÙŠÙ…ÙˆØ¬ÙŠ Ø¨Ø´ÙƒÙ„ Ù…Ù†Ø§Ø³Ø¨"""

def analyze_image(image_data):
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI Vision API"""
    try:
        # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„ØµÙˆØ±Ø© Ø¨ØµÙŠØºØ© base64
        if image_data.startswith('data:image'):
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† data URL
            image_data = image_data.split(',')[1]
        
        return {
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{image_data}"
            }
        }
    except Exception as e:
        return None

def chat(message, conversation_history=None, image_data=None):
    try:
        messages = [{"role": "system", "content": SYSTEM_MESSAGE}]
        
        if conversation_history:
            for hist_msg in conversation_history:
                messages.append({
                    "role": hist_msg.get("role", "user"),
                    "content": hist_msg.get("content", "")
                })
        
        # Ø¥Ù†Ø´Ø¡ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        user_content = [{"type": "text", "text": message}]
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ÙˆØ¬ÙˆØ¯Ø©
        if image_data:
            image_content = analyze_image(image_data)
            if image_content:
                user_content.append(image_content)
        
        messages.append({
            "role": "user",
            "content": user_content if len(user_content) > 1 else message
        })
        
        response = client.chat.completions.create(
            model="gpt-4.1-mini",
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
        
        response_message = response.choices[0].message
        tool_calls = response_message.tool_calls
        
        if tool_calls:
            messages.append(response_message)
            
            for tool_call in tool_calls:
                function_name = tool_call.function.name
                function_args = json.loads(tool_call.function.arguments)
                
                if function_name == "search_aau_knowledge":
                    function_response = search_aau_knowledge(function_args.get("query"))
                    messages.append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": function_name,
                        "content": function_response
                    })
            
            second_response = client.chat.completions.create(
                model="gpt-4.1-mini",
                messages=messages
            )
            return second_response.choices[0].message.content
        else:
            return response_message.content
    
    except Exception as e:
        return f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(json.dumps({"error": "No message provided"}))
        sys.exit(1)
    
    message = sys.argv[1]
    conversation_history = None
    image_data = None
    
    if len(sys.argv) > 2:
        try:
            conversation_history = json.loads(sys.argv[2])
        except:
            conversation_history = None
    
    if len(sys.argv) > 3:
        try:
            image_data = sys.argv[3]
        except:
            image_data = None
    
    response = chat(message, conversation_history, image_data)
    print(json.dumps({"response": response}, ensure_ascii=False))
